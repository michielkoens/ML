---
title: "Machine Learning project"
output: html_document
---

#### Executive Summary

This document describes the practical steps to predict exercise execution based on a large number of sensor measurements. Using the randomForest package on 70% of the training data results in a model with out of bound (OOB) expected error rate of 0.28%. Cross validation on the remaining 30% results in an accuracy of 99.5% (0.5% error rate). All 20 values in the final test data were predicted correctly. 

#### Data and Data Cleaning

The data contains sensor measurements which are to be used to predict the quality of weight lifting execution (column *classe* in the data). The execution can be exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

More information about the data can be found at http://groupware.les.inf.puc-rio.br/har .

I removed all columns that had half or more values N/A or empty strings. I also removed names, timestamps, and the data row number (the first 5 columns), because intuitively they should not be used to predict an activity. There were still 55 mostly numerical columns left.

#### Model

The training data was split in two parts with 70% used for training the model. I built a simple model using the randomForest package using the default settings. The details of the model creation as well as the OOB estimate of error rate and confusion matrix show that the model seems precise (Appendix 1). Because of the low estimated error rate, no further refinements were necessary and cross validation was done next. 

#### Cross Validation

The 30% of the received training data that was not used to train the model was used for cross validation. The results were about 99.5% accurate, which indicated that the model was a good candidate to run the 20 final test cases (Appendix 2). All test cases were predicted correctly (Appendix 3).



### Appendix

#### 1) Creating a Model

```{r}
library(caret)
library(randomForest)
set.seed(12345)

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "training.csv", "curl", quiet=T)
data <- read.csv("training.csv", header=T)

# remove columns with mostly NA or empty string
data <- data[,colSums(is.na(data) | data=="") < nrow(data)/2]
# remove non-relevant columns
names(data)
data <- data[,-c(1,2,3,4,5)]
# print remaining data set (before partitioning)
dim(data)

# split the data in train and test set
inTrain <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
traindata <- data[inTrain,]
testdata <- data[-inTrain,]

# create a model
modFit <- randomForest(classe ~ ., data=traindata)
modFit
```

#### 2) Cross Validation

```{r}
# remove the 'classe' column
testdata.stripped <- testdata[,-dim(testdata)[2]]

# run the prediction
pred.test <- predict(modFit, testdata.stripped)

# calculate the accuracy
testdata$predRight <- pred.test==testdata$classe
sum(testdata$predRight)/dim(testdata)[1]

```

#### 3) Predicting the 20 Test Cases

```{r}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "test.csv", "curl", quiet=T)
data <- read.csv("test.csv", header=T)

# preprocess the data as before and remove the final column containing an index
data <- data[,colSums(is.na(data) | data=="") < nrow(data)/2]
data <- data[,-c(1,2,3,4,5)]
testdata.20 <- data[,-dim(data)[2]]

# correct one factor column which has only one value in the 20 test cases
testdata.20$new_window = factor(testdata.20$new_window, levels=c("no","yes"))

# predict
pred.20 <- predict(modFit, testdata.20)
pred.20

```


